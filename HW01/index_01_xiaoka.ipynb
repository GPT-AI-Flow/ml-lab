{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b1a38eb6",
      "metadata": {},
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5c2d13e8",
      "metadata": {
        "id": "5c2d13e8"
      },
      "outputs": [],
      "source": [
        "tr_path = \"./data/covid.train.csv\"\n",
        "tt_path = \"./data/covid.test.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252a4a96",
      "metadata": {},
      "source": [
        "## Import Some Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78bcc856",
      "metadata": {
        "id": "78bcc856"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "# Sklearn\n",
        "import sklearn\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Random\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "TrsmSaTPym8K",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrsmSaTPym8K",
        "outputId": "24a8aee7-ae6b-4ff3-b8f9-fab72e2b6a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of CUDA devices: 0\n"
          ]
        }
      ],
      "source": [
        "def set_seed(seed):\n",
        "  \"\"\"为所有常见的随机性来源设置种子\"\"\"\n",
        "  np.random.seed(seed)    # 为 NumPy 设置种子\n",
        "  random.seed(seed)       # 为 Python 内置 random 模块设置种子\n",
        "  torch.manual_seed(seed) # 为 PyTorch CPU 设置种子\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed) # 为当前GPU设置种子\n",
        "    torch.cuda.manual_seed_all(seed) # 为所有GPU设置种子（如果有多块）\n",
        "\n",
        "  # 一些 CuDNN 基准优化操作本身具有不确定性，固定它们以保证可重复性\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "  # 为 Python 环境变量设置种子（影响哈希等行为）\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "myseed = 42069\n",
        "set_seed(myseed)\n",
        "\n",
        "device_count = torch.cuda.device_count()\n",
        "print(f\"Number of CUDA devices: {device_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef0bd330",
      "metadata": {},
      "source": [
        "## Some Utilies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7FAfDo1sz1RQ",
      "metadata": {
        "id": "7FAfDo1sz1RQ"
      },
      "outputs": [],
      "source": [
        "def get_device():\n",
        "    ''' Get device (if GPU is available, use GPU) '''\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
        "    plt.ylim(0.0, 5.)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure(figsize=(5, 5))\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ce3570",
      "metadata": {},
      "source": [
        "## Preprocess\n",
        "\n",
        "We have three kinds of dataset:\n",
        "- `train`: for training\n",
        "- `dev`: for validation\n",
        "- `test`: for testing (w/o target value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf797971",
      "metadata": {},
      "source": [
        "## Dataset\n",
        "\n",
        "The `COVID19Dataset` below does:\n",
        "\n",
        "- read `.csv` files\n",
        "- extract features\n",
        "- split `covid.train.csv` into train/dev sets\n",
        "- normalize features\n",
        "\n",
        "Finishing `TODO` below might make you pass medium baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4e977583",
      "metadata": {},
      "outputs": [],
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    \"\"\"Dataset for loading and preprocessing the COVID19 dataset\"\"\"\n",
        "    def __init__(self, path:str , mode='train', target_only=False):\n",
        "        self.mode = mode\n",
        "\n",
        "        # Read data into numpy arrays\n",
        "        with open(path, 'r') as fp:\n",
        "            data = list(csv.reader(fp))\n",
        "            data = np.array(data[1:])[:, 1:].astype(float)\n",
        "        \n",
        "        if not target_only:\n",
        "            feats = list(range(93))\n",
        "        else:\n",
        "            # TODO: using 40 states & 2 tested_positive features (indices = 57 & 75)\n",
        "            pass\n",
        "\n",
        "        if mode == 'test':\n",
        "            # Testing data\n",
        "            # data: 893 x 93 (40 states + day 1 (18) + day 2(18) + day 3 (17))\n",
        "            data = data[:, feats]\n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            # Training data (train/dev sets)\n",
        "            # data: 2700 x 94 (40 states + day 1 (18) + day 2(18) + day 3 (18))\n",
        "            target = data[:, -1]\n",
        "            data = data[:, feats]\n",
        "\n",
        "            # Splitting training data into train & dev sets\n",
        "            if mode == 'train':\n",
        "                indices  = [i for i in range(len(data)) if i % 10 != 0]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
        "\n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data[indices])\n",
        "            self.target = torch.FloatTensor(target[indices])\n",
        "\n",
        "        # Normalize features (you may remove this part to see what will happen)\n",
        "        self.data[:, 40:] = \\\n",
        "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
        "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
        "        self.dim = self.data.shape[1]\n",
        "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
        "              .format(mode, len(self.data), self.dim))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        # Return the size of the dataset\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "995444f7",
      "metadata": {},
      "source": [
        "## DataLoader\n",
        "\n",
        "A `DataLoader` loads data from a given Dataset into batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f9324d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "052a5c8b",
      "metadata": {},
      "source": [
        "## Deep Neural Network\n",
        "\n",
        "`NeuralNet` is an `nn.Module` designed for regression.\n",
        "The DNN consists of 2 fully-connected layers with ReLU activation.\n",
        "This module also included a function `cal_loss` for calculating loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d3ad46",
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    \"\"\"A simple fully-connected deep neural network\"\"\"\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Given input of size (batch_size x input_dim), compute output of the network\"\"\"\n",
        "        return self.net(x).squeeze(1)\n",
        "    \n",
        "    def cal_loss(self, pred, target):\n",
        "        \"\"\"Caluculate loss\"\"\"\n",
        "        # TODO: you may implement L1/L2 regularization here\n",
        "        return self.criterion(pred, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194a96a4",
      "metadata": {},
      "source": [
        "## Train/Dev/Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e249092d",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb62031e",
      "metadata": {},
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feb5d9f9",
      "metadata": {},
      "source": [
        "### Testing"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
